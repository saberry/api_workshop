---
title: "API Examples"
format: html
---

The Application Programming Interface is one of the greatest things that you can use for acquiring data. 

We are going to be using just a few packages to make the API calls and get our data together:

```{r}
#| warning: false
#| message: false
library(httr2)
library(jsonlite)
```

## Free and Unkeyed APIs

Let's start by finding some coordinates for South Bend:

```{r}
#| warning: false
#| message: false
town <- "South%20Bend,IN"

link <- glue::glue(
  "https://geocode.maps.co/search?q={town}"
)

lat_lon_req <- request(link) %>% 
  req_perform()

lat_lon_return <- resp_body_json(lat_lon_req)

lat <- lat_lon_return[[1]]$lat

lon <- lat_lon_return[[1]]$lon
```

Now that we have those coordinates, we can turn to <a href='https://open-meteo.com/'>Open-Meteo</a> to grab some weather data. Not only is it free and unkeyed, but it has very little in the way of **rate limits**. It is also a good example of building up the link.

:::{.callout-important}
Every API is different, so you will need to do a little reading to see how many requests you are allowed for any given time period -- some APIs are generous and others are not. 
:::

```{r}
#| warning: false
#| message: false
link <- glue::glue(
  "https://archive-api.open-meteo.com/v1/archive?latitude={lat}&longitude={lon}&start_date=2012-01-01&end_date=2023-10-31&daily=temperature_2m_max,temperature_2m_min,temperature_2m_mean,snowfall_sum&temperature_unit=fahrenheit&precipitation_unit=inch&timezone=America%2FNew_York"
)

weather_request <- request(link) %>%
  req_perform()
```

Now that we have made our request, we need to do just a little parsing to pull out data in.

```{r}
#| warning: false
#| message: false
weather_content <- resp_body_string(weather_request)

weather_data <- fromJSON(weather_content)
```

Naturally, we are left with a list; parsing it won't be any trouble.

```{r}
#| warning: false
#| message: false
sb_daily_weather <- as.data.frame(weather_data$daily)

sb_daily_weather$time <- lubridate::ymd(sb_daily_weather$time)
```

This data will lend itself nicely to a time-based viz:

```{r}
#| warning: false
#| message: false
library(plotly)

plot_ly(sb_daily_weather, type = 'scatter', mode = 'lines') %>%
  add_trace(x = ~time, y = ~temperature_2m_max, name = 'max_temp') %>%
  add_trace(x = ~time, y = ~temperature_2m_min, name = 'min_temp') %>% 
  layout(xaxis = list(rangeslider = list(visible = TRUE)))
```

Just in the event that you were curious about snowfall:

```{r}
#| warning: false
#| message: false
plot_ly(sb_daily_weather, type = 'scatter', mode = 'line') %>%
  add_trace(x = ~time, y = ~snowfall_sum, name = 'Snowfall') %>% 
  layout(xaxis = list(rangeslider = list(visible = TRUE)))
```

## Keyed APIs

Many APIs want you to have a **key** -- essentially a identifier -- so that they can place limits on the amount of requests that you make. 

A lot of places will make you sign up for an account and create an application. Let's see what we can do with <a href='https://developer.kroger.com/'>Kroger</a>. 

After you create an account, you can get a key and a secret. 

Generally, you don't want to put your key and secret out there, so you can just set them in your Rprofile and then call them later:

```{r}
#| eval: false
Sys.setenv(kroger_k = "your_key")
Sys.setenv(kroger_s = "your_secret")
```

Then you can load them:

```{r}
kroger_k <- Sys.getenv("kroger_k")

kroger_s <- Sys.getenv("kroger_s")
```

:::{.callout-warning}
I am not always very good with my keys, but you don't want to be like me. Keep your keys secure and don't post them on GitHub! Tossing a Google key out into the wild could be a disaster if you don't have it locked down. 
:::

The Kroger API sits right in the middle of the easy/complicated continuum. 

```{r}
#| eval: false
auth_request <- request("https://api.kroger.com/v1/connect/oauth2/token") %>%
  req_method("POST") %>%
  req_headers("Content-Type" = "application/x-www-form-urlencoded") %>%
  req_body_form(grant_type = "client_credentials", 
                scope = "product.compact") %>%
  req_auth_basic(username = kroger_k, password = kroger_s) %>%
  req_perform()

access_token <- resp_body_json(auth_request)$access_token
```

```{r}
#| eval: false
location_link <- "https://api.kroger.com/v1/locations?filter.zipCode.near=46545"

location_request <- request(location_link) %>%
  req_headers("Cache-Control" = "no-cache", 
              "Content-Type" = "application/json; charset=utf-8") %>%
  req_auth_bearer_token(access_token) %>%
  req_perform()

close_locations <- resp_body_json(location_request)

location_id <- close_locations$data[[1]]$locationId
```

```{r}
#| eval: false
search_term <- "pumpkin%20cookies"

product_link <- glue::glue(
  "https://api.kroger.com/v1/products?filter.term={search_term}&filter.locationId={location_id}"
)

product_request <- request(product_link) %>%
  req_headers("Cache-Control" = "no-cache", 
              "Content-Type" = "application/json; charset=utf-8") %>%
  req_auth_bearer_token(access_token) %>% #req_dry_run(quiet = FALSE, redact_headers = FALSE)
  req_perform()

product_data <- resp_body_json(product_request)
```

## Private APIs

As you navigate the web, you'll find a ton of interesting looking data in tables and other places. If you like to do just a little bit of exploring, you can typically find where that data lives!

```{r}
#| warning: false
#| message: false
week_nums <- 1:18
season <- 2021:2022

week_season <- expand.grid(
  week = week_nums, 
  season = season
)

data_function <- function(week, season) {
  link <- glue::glue(
    "https://nextgenstats.nfl.com/api/statboard/receiving?season={season}&seasonType=REG&week={week}"
  )
  
  output <- request(link) %>% 
    req_headers("Host" = "nextgenstats.nfl.com", 
                "Referer" = "https://nextgenstats.nfl.com/stats/receiving/2022/REG/1",
                "User-Agent" = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/119.0") %>% 
    req_perform() %>% 
    resp_body_string() %>% 
    fromJSON()
  
  week_stat <- output$stats
  
  week_stat <- week_stat[, -grep("player\\b", colnames(week_stat))]
  
  week_stat$season <- output$season
  
  week_stat$week <- output$week
  
  return(week_stat)
}

all_stats <- mapply(data_function, 
                    week_season$week, 
                    week_season$season, 
                    SIMPLIFY = FALSE)

all_stats <- do.call(rbind, all_stats)

rmarkdown::paged_table(all_stats)
```

### Python

```{python}
#| warning: false
#| message: false
import pandas as pd
import requests

url = "https://nextgenstats.nfl.com/api/statboard/receiving?season=2021&seasonType=REG"

headers = {
  "Host": "nextgenstats.nfl.com", 
  "Referer": "https://nextgenstats.nfl.com/stats/receiving/2022/REG/1",
  "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/119.0"
  }

nfl_request = requests.get(url, headers=headers)

nfl_data = nfl_request.json()

nfl_stats = nfl_data['stats']

nfl_df = pd.DataFrame(nfl_stats)

nfl_df
```

Now let's grab all of the individual weeks for 2021 and 2022:

```{python}
#| warning: false
#| message: false
import itertools

week_nums = list(range(1, 18))

season = list(range(2021, 2023))

week_season = pd.DataFrame(
  list(itertools.product(week_nums, season)), columns=['week', 'season']
  )
  
def data_function(week, season):
  url = f"https://nextgenstats.nfl.com/api/statboard/receiving?season={season}&seasonType=REG&week={week}"
  
  nfl_request = requests.get(url, headers=headers)
  
  nfl_data = nfl_request.json()
  
  nfl_stats = nfl_data['stats']
  
  nfl_df = pd.DataFrame(nfl_stats)
  
  nfl_df['season'] = nfl_data['season']
  
  nfl_df['week'] = nfl_data['week']
  
  return(nfl_df)

all_stats = [data_function(x, y) for x,y in zip(week_season['week'], week_season['season'])]

all_stats = pd.concat(all_stats)

all_stats
```